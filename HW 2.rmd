---
title: "HW 2 Student"
author: "Andy Ackerman"
date: "10/17/2023"
output: 
  html_document:
    number_sections: true
---

This homework is meant to illustrate the methods of classification algorithms as well as their potential pitfalls.  In class, we demonstrated K-Nearest-Neighbors using the `iris` dataset.  Today I will give you a different subset of this same data, and you will train a KNN classifier.  

```{r, echo = FALSE}
set.seed(123)
library(class)

df <- data(iris) 

normal <-function(x) {
  (x -min(x))/(max(x)-min(x))   
}

iris_norm <- as.data.frame(lapply(iris[,c(1,2,3,4)], normal))

subset <- c(1:45, 58, 60:70, 82, 94, 110:150)
iris_train <- iris_norm[subset,] 
iris_test <- iris_norm[-subset,] 

iris_target_category <- iris[subset,5]
iris_test_category <- iris[-subset,5]


```

#
Above, I have given you a training-testing partition.  Train the KNN with $K = 5$ on the training data and use this to classify the 50 test observations.  Once you have classified the test observations, create a contingency table -- like we did in class -- to evaluate which observations your algorithm is misclassifying.   

```{r}
set.seed(123)


pr<-knn(iris_train,iris_test,cl=iris_target_category,k=5)
#don't do three because there are 3 class labels and cant be divisible by it
tab<-table(pr, iris_test_category)
tab

accuracy<-function(x){
  sum(diag(x))/sum(rowSums(x))*100
}
accuracy(tab)
```

#

Discuss your results.  If you have done this correctly, you should have a classification error rate that is roughly 20% higher than what we observed in class.  Why is this the case? In particular run a summary of the `iris_test_category` as well as `iris_target_category` and discuss how this plays a role in your answer.  

*STUDENT INPUT* 
Given the results, I found that all of the Setosa and Versicolor were classified correctly. However, eleven of the 20 Virginica were misclassified as Versicolor with nine classified correctly. I found that the classification error rate was roughly 22 percent with an accuracy of 78 percent. Given the summarys of the test and target category, this misclassifcation makes sense due to the large number of versicolor in the test data. This high number of versicolor caused the virginica to be misclassified as versicolor since most of the options for the the nearest neighbors function to choose from was predominatly versicolor. Put in another way, the testing data was not reflective of the distribution of observations within each category and this explains the low performance of K nearest neighbors.
```{r}
summary(iris_target_category)
summary(iris_test_category)
```


#

Build a github repository to store your homework assignments.  Share the link in this file.  

*STUDENT INPUT*


https://github.com/cregister1/STOR-390-Homework 
